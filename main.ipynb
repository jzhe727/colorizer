{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19752a7f-f2d2-49fb-821f-b22a9b86869f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data.ipynb\n",
      "importing Jupyter notebook from CUnet.ipynb\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 2, 256, 256])\n",
      "importing Jupyter notebook from eccv16.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import imutils\n",
    "from skimage import color\n",
    "from skimage.util.dtype import convert\n",
    "import import_ipynb #pip install import-ipynb\n",
    "\n",
    "from data import ImageNet, VisionDataset\n",
    "from CUnet import CUNet\n",
    "from eccv16 import eccv16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf5105-55d4-43ca-a373-6e83621a3827",
   "metadata": {},
   "source": [
    "## Define models and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97432a8-63f0-4359-a62e-78958ade4699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cu_model = CUNet()\n",
    "ecc_model = eccv16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81c6ba2-5ec3-4887-b17a-33f6371f1cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "ImageNet_train_dataset = ImageNet(root=\"./imagenet/train\", transform=trans, size=1000)\n",
    "ImageNet_eval_dataset = ImageNet(root=\"./imagenet/val\", transform=trans, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa18c3b-81ec-4a8c-8dd1-740e215ac82a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader_imagenet = DataLoader(ImageNet_train_dataset, batch_size=32, shuffle=True)\n",
    "eval_dataloader_imagenet = DataLoader(ImageNet_eval_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3d129-0394-4a16-a346-c9123e42d80a",
   "metadata": {},
   "source": [
    "## Define Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a3d7e5-e1ce-473a-9c00-1c5466872e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.SGD(cu_model.parameters(), lr = 0.1) #change as needed\n",
    "loss_function = torch.nn.MSELoss() #change as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fdb52-700a-4f49-becc-9b485a683f33",
   "metadata": {},
   "source": [
    "## Define Train and eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b404f87f-107b-4533-ab71-f0232172291c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(dataloader, model, device, optimizer, loss_function, epochs=1):\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_index,(inputs, expected) in enumerate(dataloader):\n",
    "            optimizer.zero_grad() \n",
    "            inputs = inputs.to(device)\n",
    "            expected = expected.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, expected)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*len(expected)\n",
    "        filename = f'model/{type(model).__name__}_{epoch}_{train_loss}.pth'\n",
    "        torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34fe5fb3-8e4c-40da-aee8-7bf03dab23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(dataloader, model, device, optimizer, loss_function, epochs=1):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for batch_index,(inputs, expected) in enumerate(dataloader):\n",
    "        # inputs = torchvision.transforms.ToTensor(train_dataloader_imagenet.resize_image(lightness))\n",
    "        # expected = torchvision.transforms.ToTensor(train_dataloader_imagenet.resize_image(colors))\n",
    "        # inputs.type(torch.float32)\n",
    "        # expected.type(torch.float32)\n",
    "        print(type(inputs))\n",
    "        inputs = inputs.to(device)\n",
    "        expected = expected.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, expected)\n",
    "        val_loss += loss.item()*len(expected)\n",
    "    avg_val_loss = val_loss/len(eval_dataloader_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff1e82b-1de1-415c-af72-6e6f25939a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def name_to_epoch(name):\n",
    "    _, a = name.split(\"/\")\n",
    "    _, epoch, _ = name.split(\"_\") #name, epoch, avg_l.pth\n",
    "    return(int(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349a78f9-c003-4810-934a-119af7b0e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(train_dataloader_imagenet, cu_model, device, optimizer, loss_function, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba56415-ee81-40b5-94e8-2ac0e6114b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_dataloader_imagenet, ecc_model, device, optimizer, loss_function, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac991b0-1410-4068-a76b-54f8936890db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9e9d3-bcdd-4877-a936-c2cf3a57d805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
